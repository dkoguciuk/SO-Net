{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "activation: relu\n",
      "batch_size: 8\n",
      "bn_momentum: 0.1\n",
      "bn_momentum_decay: 0.6\n",
      "bn_momentum_decay_step: None\n",
      "checkpoints_dir: /workspace/ModelNet/SO-Net/SO-Net/checkpoints/\n",
      "classes: 40\n",
      "dataroot: /workspace/ModelNet/modelnet40-normal_numpy/\n",
      "dataset: modelnet\n",
      "device: cuda:0\n",
      "display_id: 200\n",
      "display_winsize: 256\n",
      "dropout: 0.7\n",
      "feature_num: 1024\n",
      "gpu_id: 0\n",
      "input_pc_num: 5000\n",
      "k: 3\n",
      "lr: 0.001\n",
      "nThreads: 8\n",
      "name: train\n",
      "node_num: 64\n",
      "normalization: batch\n",
      "pretrain: None\n",
      "pretrain_lr_ratio: 1\n",
      "random_pc_dropout_lower_limit: 1\n",
      "rot_horizontal: False\n",
      "rot_perturbation: False\n",
      "som_k: 9\n",
      "som_k_type: avg\n",
      "surface_normal: True\n",
      "translation_perturbation: False\n",
      "-------------- End ----------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "sys.argv = ['options', '--classes', '40', '--dataroot', '/workspace/ModelNet/modelnet40-normal_numpy/',\n",
    "           '--checkpoints_dir', '/workspace/ModelNet/SO-Net/SO-Net/checkpoints/']\n",
    "from modelnet.options import Options\n",
    "opt = Options().parse()  # set CUDA_VISIBLE_DEVICES before import torch\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from models.classifier import Model\n",
    "from data.modelnet_shrec_loader import ModelNet_Shrec_Loader\n",
    "from util.visualizer import Visualizer\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = ModelNet_Shrec_Loader(opt.dataroot, 'test', opt)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=opt.batch_size, shuffle=False, num_workers=opt.nThreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating train\n",
      "Evaluating model_7\n",
      "Evaluating model_6\n",
      "Evaluating model_2\n",
      "Evaluating model_4\n",
      "Evaluating model_10\n",
      "Evaluating model_1\n",
      "Evaluating model_5\n",
      "Evaluating model_3\n",
      "Evaluating model_8\n",
      "Evaluating model_9\n"
     ]
    }
   ],
   "source": [
    "model_probabilities_list = []\n",
    "for model_name in os.listdir(opt.checkpoints_dir):\n",
    "    print('Evaluating ' + model_name)\n",
    "    if 'model' not in model_name:\n",
    "        continue\n",
    "    # create model, optionally load pre-trained model\n",
    "    model = Model(opt)\n",
    "    model_path = os.path.join(opt.checkpoints_dir, model_name)\n",
    "    checkpoints = [x for x in os.listdir(model_path) if os.path.splitext(x)[-1] == '.pth']\n",
    "    checkpoints = sorted(checkpoints, key=lambda x: int(x.split('_')[0]))[-2:]\n",
    "    for item in checkpoints:\n",
    "        if item.split('_')[-1] == 'classifier.pth':\n",
    "            ckp_classifier = item\n",
    "        if item.split('_')[-1] == 'encoder.pth':\n",
    "            ckp_encoder = item\n",
    "    classifier_ckp_path = os.path.join(model_path, ckp_classifier)\n",
    "    encoder_ckp_path = os.path.join(model_path, ckp_encoder)\n",
    "    model.encoder.load_state_dict(torch.load(encoder_ckp_path))\n",
    "    model.classifier.load_state_dict(torch.load(classifier_ckp_path))\n",
    "    model.test_loss.data.zero_()\n",
    "    model.test_accuracy.data.zero_()\n",
    "    model_probabilities = []\n",
    "    gt_labels = []\n",
    "    for i, data in enumerate(testloader):\n",
    "        input_pc, input_sn, input_label, input_node, input_node_knn_I = data\n",
    "        model.set_input(input_pc, input_sn, input_label, input_node, input_node_knn_I)\n",
    "        model.test_model()\n",
    "        model_probabilities.append(model.score.data)\n",
    "        gt_labels.append(model.input_label.cpu())\n",
    "\n",
    "    model_probabilities = torch.cat(model_probabilities, 0).cpu().numpy()\n",
    "    gt_labels = torch.cat(gt_labels, 0).numpy()\n",
    "    model_probabilities_list.append(model_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean model accuracy = 0.9264991896272285\n",
      "Max model accuracy = 0.9294975688816856\n",
      "Ensembling (mode aggregation) accuracy = 0.936385737439222\n",
      "Ensembling (mean aggregation) accuracy = 0.936385737439222\n"
     ]
    }
   ],
   "source": [
    "models_probabilities = np.stack(model_probabilities_list)\n",
    "models_predictions = np.argmax(models_probabilities, -1)\n",
    "correct_mask = np.equal(models_predictions, gt_labels).astype(np.float)\n",
    "models_accuracy = np.mean(correct_mask, -1)\n",
    "mean_accuracy = np.mean(models_accuracy)\n",
    "max_accuracy = np.max(models_accuracy)\n",
    "print('Mean model accuracy =', mean_accuracy)\n",
    "print('Max model accuracy =', max_accuracy)\n",
    "\n",
    "preditions_ens = np.squeeze(stats.mode(models_predictions)[0])\n",
    "correct_mask_ens = np.equal(preditions_ens, gt_labels).astype(np.float)\n",
    "accuracy_ens = np.mean(correct_mask_ens)\n",
    "print('Ensembling (mode aggregation) accuracy =', accuracy_ens)\n",
    "\n",
    "preditions_ens = np.argmax(np.mean(models_probabilities, 0), -1)\n",
    "correct_mask_ens = np.equal(preditions_ens, gt_labels).astype(np.float)\n",
    "accuracy_ens = np.mean(correct_mask_ens)\n",
    "print('Ensembling (mean aggregation) accuracy =', accuracy_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2468, 40, 10) (2468,)\n"
     ]
    }
   ],
   "source": [
    "models_probabilities_t = np.transpose(models_probabilities, axes=(1, 2, 0))\n",
    "print(models_probabilities_t.shape, gt_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('probabilities.npy', models_probabilities_t)\n",
    "np.save('true_labels.npy', gt_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
